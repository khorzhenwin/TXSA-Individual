{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Khor Zhen Win - TP055619\n",
    "Individual Assignment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to install the required libraries\n",
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to install all NLTK data\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It is one thing to automatically detect that a particular word occurs in a text, and to display some words that appear in the same context. However, we can also determine the location of a word in the text: how many words from the beginning it appears. This positional information can be displayed using a dispersion plot. Each stripe represents an instance of a word, and each row represents the entire text.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data from Data_1.txt where each line is a string\n",
    "with open('Data_1.txt') as f:\n",
    "    data1 = f.readlines()\n",
    "    \n",
    "# remove whitespace characters like `\\n` at the end of each line\n",
    "# this joins all the data into one paragraph of a single string\n",
    "data1 = [x.strip() for x in data1]\n",
    "data1 = ' '.join(data1)\n",
    "data1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Form Tokenization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It is one thing to automatically detect that a particular word occurs in a text, and to display some words that appear in the same context.', 'However, we can also determine the location of a word in the text: how many words from the beginning it appears.', 'This positional information can be displayed using a dispersion plot.', 'Each stripe represents an instance of a word, and each row represents the entire text.']\n",
      "\n",
      "Number of sentences:  4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(data1, language='english')\n",
    "print(sentences)\n",
    "print()\n",
    "print(\"Number of sentences: \", len(sentences))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: It is one thing to automatically detect that a particular word occurs in a text, and to display some words that appear in the same context.\n",
      "\n",
      "Sentence 2: However, we can also determine the location of a word in the text: how many words from the beginning it appears.\n",
      "\n",
      "Sentence 3: This positional information can be displayed using a dispersion plot.\n",
      "\n",
      "Sentence 4: Each stripe represents an instance of a word, and each row represents the entire text.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sentences)):\n",
    "    print(\"Sentence \" + str(i+1) + \": \" + sentences[i])\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Tokenization\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  26 tokens in sentence 1\n",
      "\n",
      "There are  21 tokens in sentence 2\n",
      "\n",
      "There are  10 tokens in sentence 3\n",
      "\n",
      "There are  15 tokens in sentence 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using python split function to split sentences into words with default delimiter of space\n",
    "sentence_token_1_split = sentences[0].split()\n",
    "sentence_token_2_split = sentences[1].split()\n",
    "sentence_token_3_split = sentences[2].split()\n",
    "sentence_token_4_split = sentences[3].split()\n",
    "\n",
    "print(\"There are \", len(sentence_token_1_split), \"tokens in sentence 1\\n\")\n",
    "print(\"There are \", len(sentence_token_2_split), \"tokens in sentence 2\\n\")\n",
    "print(\"There are \", len(sentence_token_3_split), \"tokens in sentence 3\\n\")\n",
    "print(\"There are \", len(sentence_token_4_split), \"tokens in sentence 4\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence 1</th>\n",
       "      <th>Sentence 2</th>\n",
       "      <th>Sentence 3</th>\n",
       "      <th>Sentence 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It</td>\n",
       "      <td>However,</td>\n",
       "      <td>This</td>\n",
       "      <td>Each</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>we</td>\n",
       "      <td>positional</td>\n",
       "      <td>stripe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>can</td>\n",
       "      <td>information</td>\n",
       "      <td>represents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thing</td>\n",
       "      <td>also</td>\n",
       "      <td>can</td>\n",
       "      <td>an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>determine</td>\n",
       "      <td>be</td>\n",
       "      <td>instance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>automatically</td>\n",
       "      <td>the</td>\n",
       "      <td>displayed</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>detect</td>\n",
       "      <td>location</td>\n",
       "      <td>using</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>that</td>\n",
       "      <td>of</td>\n",
       "      <td>a</td>\n",
       "      <td>word,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>dispersion</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>particular</td>\n",
       "      <td>word</td>\n",
       "      <td>plot.</td>\n",
       "      <td>each</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>word</td>\n",
       "      <td>in</td>\n",
       "      <td></td>\n",
       "      <td>row</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>occurs</td>\n",
       "      <td>the</td>\n",
       "      <td></td>\n",
       "      <td>represents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>in</td>\n",
       "      <td>text:</td>\n",
       "      <td></td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>a</td>\n",
       "      <td>how</td>\n",
       "      <td></td>\n",
       "      <td>entire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>text,</td>\n",
       "      <td>many</td>\n",
       "      <td></td>\n",
       "      <td>text.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>and</td>\n",
       "      <td>words</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>to</td>\n",
       "      <td>from</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>display</td>\n",
       "      <td>the</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>some</td>\n",
       "      <td>beginning</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>words</td>\n",
       "      <td>it</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>that</td>\n",
       "      <td>appears.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>appear</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>in</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>the</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>same</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>context.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentence 1 Sentence 2   Sentence 3  Sentence 4\n",
       "0              It   However,         This        Each\n",
       "1              is         we   positional      stripe\n",
       "2             one        can  information  represents\n",
       "3           thing       also          can          an\n",
       "4              to  determine           be    instance\n",
       "5   automatically        the    displayed          of\n",
       "6          detect   location        using           a\n",
       "7            that         of            a       word,\n",
       "8               a          a   dispersion         and\n",
       "9      particular       word        plot.        each\n",
       "10           word         in                      row\n",
       "11         occurs        the               represents\n",
       "12             in      text:                      the\n",
       "13              a        how                   entire\n",
       "14          text,       many                    text.\n",
       "15            and      words                         \n",
       "16             to       from                         \n",
       "17        display        the                         \n",
       "18           some  beginning                         \n",
       "19          words         it                         \n",
       "20           that   appears.                         \n",
       "21         appear                                    \n",
       "22             in                                    \n",
       "23            the                                    \n",
       "24           same                                    \n",
       "25       context.                                    "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# detect the longest length of the list of the 4 variables\n",
    "max_len = max(len(sentence_token_1_split), len(sentence_token_2_split), len(sentence_token_3_split), len(sentence_token_4_split))\n",
    "\n",
    "# normalize all the 4 variables into the max length (fill the empty space with NaN)\n",
    "sentence_token_1_split = sentence_token_1_split + (max_len - len(sentence_token_1_split)) * [np.nan]\n",
    "sentence_token_2_split = sentence_token_2_split + (max_len - len(sentence_token_2_split)) * [np.nan]\n",
    "sentence_token_3_split = sentence_token_3_split + (max_len - len(sentence_token_3_split)) * [np.nan]\n",
    "sentence_token_4_split = sentence_token_4_split + (max_len - len(sentence_token_4_split)) * [np.nan]\n",
    "\n",
    "# create a dataframe with the 4 variables (show NaN as empty space)\n",
    "df_token_split = pd.DataFrame({'Sentence 1': sentence_token_1_split, \n",
    "                              'Sentence 2': sentence_token_2_split, \n",
    "                              'Sentence 3': sentence_token_3_split, \n",
    "                              'Sentence 4': sentence_token_4_split}).fillna('')\n",
    "df_token_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regular Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  27 tokens in sentence 1\n",
      "\n",
      "There are  22 tokens in sentence 2\n",
      "\n",
      "There are  11 tokens in sentence 3\n",
      "\n",
      "There are  16 tokens in sentence 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using regex to split sentences into words and remove empty strings\n",
    "sentence_token_1_re = re.split(r'\\W+', sentences[0])\n",
    "sentence_token_2_re = re.split(r'\\W+', sentences[1])\n",
    "sentence_token_3_re = re.split(r'\\W+', sentences[2])\n",
    "sentence_token_4_re = re.split(r'\\W+', sentences[3])\n",
    "\n",
    "print(\"There are \", len(sentence_token_1_re), \"tokens in sentence 1\\n\")\n",
    "print(\"There are \", len(sentence_token_2_re), \"tokens in sentence 2\\n\")\n",
    "print(\"There are \", len(sentence_token_3_re), \"tokens in sentence 3\\n\")\n",
    "print(\"There are \", len(sentence_token_4_re), \"tokens in sentence 4\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " 'is',\n",
       " 'one',\n",
       " 'thing',\n",
       " 'to',\n",
       " 'automatically',\n",
       " 'detect',\n",
       " 'that',\n",
       " 'a',\n",
       " 'particular',\n",
       " 'word',\n",
       " 'occurs',\n",
       " 'in',\n",
       " 'a',\n",
       " 'text',\n",
       " 'and',\n",
       " 'to',\n",
       " 'display',\n",
       " 'some',\n",
       " 'words',\n",
       " 'that',\n",
       " 'appear',\n",
       " 'in',\n",
       " 'the',\n",
       " 'same',\n",
       " 'context',\n",
       " '']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_token_1_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  26 tokens in sentence 1\n",
      "\n",
      "There are  21 tokens in sentence 2\n",
      "\n",
      "There are  10 tokens in sentence 3\n",
      "\n",
      "There are  15 tokens in sentence 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filtering out empty strings\n",
    "sentence_token_1_re = list(filter(None, sentence_token_1_re))\n",
    "sentence_token_2_re = list(filter(None, sentence_token_2_re))\n",
    "sentence_token_3_re = list(filter(None, sentence_token_3_re))\n",
    "sentence_token_4_re = list(filter(None, sentence_token_4_re))\n",
    "\n",
    "print(\"There are \", len(sentence_token_1_re), \"tokens in sentence 1\\n\")\n",
    "print(\"There are \", len(sentence_token_2_re), \"tokens in sentence 2\\n\")\n",
    "print(\"There are \", len(sentence_token_3_re), \"tokens in sentence 3\\n\")\n",
    "print(\"There are \", len(sentence_token_4_re), \"tokens in sentence 4\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence 1</th>\n",
       "      <th>Sentence 2</th>\n",
       "      <th>Sentence 3</th>\n",
       "      <th>Sentence 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It</td>\n",
       "      <td>However</td>\n",
       "      <td>This</td>\n",
       "      <td>Each</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>we</td>\n",
       "      <td>positional</td>\n",
       "      <td>stripe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>can</td>\n",
       "      <td>information</td>\n",
       "      <td>represents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thing</td>\n",
       "      <td>also</td>\n",
       "      <td>can</td>\n",
       "      <td>an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>determine</td>\n",
       "      <td>be</td>\n",
       "      <td>instance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>automatically</td>\n",
       "      <td>the</td>\n",
       "      <td>displayed</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>detect</td>\n",
       "      <td>location</td>\n",
       "      <td>using</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>that</td>\n",
       "      <td>of</td>\n",
       "      <td>a</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>dispersion</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>particular</td>\n",
       "      <td>word</td>\n",
       "      <td>plot</td>\n",
       "      <td>each</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>word</td>\n",
       "      <td>in</td>\n",
       "      <td></td>\n",
       "      <td>row</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>occurs</td>\n",
       "      <td>the</td>\n",
       "      <td></td>\n",
       "      <td>represents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>in</td>\n",
       "      <td>text</td>\n",
       "      <td></td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>a</td>\n",
       "      <td>how</td>\n",
       "      <td></td>\n",
       "      <td>entire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>text</td>\n",
       "      <td>many</td>\n",
       "      <td></td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>and</td>\n",
       "      <td>words</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>to</td>\n",
       "      <td>from</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>display</td>\n",
       "      <td>the</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>some</td>\n",
       "      <td>beginning</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>words</td>\n",
       "      <td>it</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>that</td>\n",
       "      <td>appears</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>appear</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>in</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>the</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>same</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>context</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentence 1 Sentence 2   Sentence 3  Sentence 4\n",
       "0              It    However         This        Each\n",
       "1              is         we   positional      stripe\n",
       "2             one        can  information  represents\n",
       "3           thing       also          can          an\n",
       "4              to  determine           be    instance\n",
       "5   automatically        the    displayed          of\n",
       "6          detect   location        using           a\n",
       "7            that         of            a        word\n",
       "8               a          a   dispersion         and\n",
       "9      particular       word         plot        each\n",
       "10           word         in                      row\n",
       "11         occurs        the               represents\n",
       "12             in       text                      the\n",
       "13              a        how                   entire\n",
       "14           text       many                     text\n",
       "15            and      words                         \n",
       "16             to       from                         \n",
       "17        display        the                         \n",
       "18           some  beginning                         \n",
       "19          words         it                         \n",
       "20           that    appears                         \n",
       "21         appear                                    \n",
       "22             in                                    \n",
       "23            the                                    \n",
       "24           same                                    \n",
       "25        context                                    "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# detect the longest length of the list of the 4 variables\n",
    "max_len = max(len(sentence_token_1_re), len(sentence_token_2_re), len(sentence_token_3_re), len(sentence_token_4_re))\n",
    "\n",
    "# normalize all the 4 variables into the max length (fill the empty space with NaN)\n",
    "sentence_token_1_re = sentence_token_1_re + (max_len - len(sentence_token_1_re)) * [np.nan]\n",
    "sentence_token_2_re = sentence_token_2_re + (max_len - len(sentence_token_2_re)) * [np.nan]\n",
    "sentence_token_3_re = sentence_token_3_re + (max_len - len(sentence_token_3_re)) * [np.nan]\n",
    "sentence_token_4_re = sentence_token_4_re + (max_len - len(sentence_token_4_re)) * [np.nan]\n",
    "\n",
    "# create a dataframe with the 4 variables (show NaN as empty space)\n",
    "df_token_re = pd.DataFrame({'Sentence 1': sentence_token_1_re, \n",
    "                              'Sentence 2': sentence_token_2_re, \n",
    "                              'Sentence 3': sentence_token_3_re, \n",
    "                              'Sentence 4': sentence_token_4_re}).fillna('')\n",
    "df_token_re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NLTK Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  28 tokens in sentence 1\n",
      "\n",
      "There are  24 tokens in sentence 2\n",
      "\n",
      "There are  11 tokens in sentence 3\n",
      "\n",
      "There are  17 tokens in sentence 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using nltk to tokenize the sentences\n",
    "sentence_token_1_nltk = nltk.word_tokenize(sentences[0])\n",
    "sentence_token_2_nltk = nltk.word_tokenize(sentences[1])\n",
    "sentence_token_3_nltk = nltk.word_tokenize(sentences[2])\n",
    "sentence_token_4_nltk = nltk.word_tokenize(sentences[3])\n",
    "\n",
    "print(\"There are \", len(sentence_token_1_nltk), \"tokens in sentence 1\\n\")\n",
    "print(\"There are \", len(sentence_token_2_nltk), \"tokens in sentence 2\\n\")\n",
    "print(\"There are \", len(sentence_token_3_nltk), \"tokens in sentence 3\\n\")\n",
    "print(\"There are \", len(sentence_token_4_nltk), \"tokens in sentence 4\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence 1</th>\n",
       "      <th>Sentence 2</th>\n",
       "      <th>Sentence 3</th>\n",
       "      <th>Sentence 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It</td>\n",
       "      <td>However</td>\n",
       "      <td>This</td>\n",
       "      <td>Each</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>,</td>\n",
       "      <td>positional</td>\n",
       "      <td>stripe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>we</td>\n",
       "      <td>information</td>\n",
       "      <td>represents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thing</td>\n",
       "      <td>can</td>\n",
       "      <td>can</td>\n",
       "      <td>an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>also</td>\n",
       "      <td>be</td>\n",
       "      <td>instance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>automatically</td>\n",
       "      <td>determine</td>\n",
       "      <td>displayed</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>detect</td>\n",
       "      <td>the</td>\n",
       "      <td>using</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>that</td>\n",
       "      <td>location</td>\n",
       "      <td>a</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a</td>\n",
       "      <td>of</td>\n",
       "      <td>dispersion</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>particular</td>\n",
       "      <td>a</td>\n",
       "      <td>plot</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>word</td>\n",
       "      <td>word</td>\n",
       "      <td>.</td>\n",
       "      <td>each</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>occurs</td>\n",
       "      <td>in</td>\n",
       "      <td></td>\n",
       "      <td>row</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>in</td>\n",
       "      <td>the</td>\n",
       "      <td></td>\n",
       "      <td>represents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>a</td>\n",
       "      <td>text</td>\n",
       "      <td></td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>text</td>\n",
       "      <td>:</td>\n",
       "      <td></td>\n",
       "      <td>entire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>,</td>\n",
       "      <td>how</td>\n",
       "      <td></td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>and</td>\n",
       "      <td>many</td>\n",
       "      <td></td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>to</td>\n",
       "      <td>words</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>display</td>\n",
       "      <td>from</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>some</td>\n",
       "      <td>the</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>words</td>\n",
       "      <td>beginning</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>that</td>\n",
       "      <td>it</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>appear</td>\n",
       "      <td>appears</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>in</td>\n",
       "      <td>.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>the</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>same</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>context</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sentence 1 Sentence 2   Sentence 3  Sentence 4\n",
       "0              It    However         This        Each\n",
       "1              is          ,   positional      stripe\n",
       "2             one         we  information  represents\n",
       "3           thing        can          can          an\n",
       "4              to       also           be    instance\n",
       "5   automatically  determine    displayed          of\n",
       "6          detect        the        using           a\n",
       "7            that   location            a        word\n",
       "8               a         of   dispersion           ,\n",
       "9      particular          a         plot         and\n",
       "10           word       word            .        each\n",
       "11         occurs         in                      row\n",
       "12             in        the               represents\n",
       "13              a       text                      the\n",
       "14           text          :                   entire\n",
       "15              ,        how                     text\n",
       "16            and       many                        .\n",
       "17             to      words                         \n",
       "18        display       from                         \n",
       "19           some        the                         \n",
       "20          words  beginning                         \n",
       "21           that         it                         \n",
       "22         appear    appears                         \n",
       "23             in          .                         \n",
       "24            the                                    \n",
       "25           same                                    \n",
       "26        context                                    \n",
       "27              .                                    "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# detect the longest length of the list of the 4 variables\n",
    "max_len = max(len(sentence_token_1_nltk), len(sentence_token_2_nltk), len(sentence_token_3_nltk), len(sentence_token_4_nltk))\n",
    "\n",
    "# normalize all the 4 variables into the max length (fill the empty space with NaN)\n",
    "sentence_token_1_nltk = sentence_token_1_nltk + (max_len - len(sentence_token_1_nltk)) * [np.nan]\n",
    "sentence_token_2_nltk = sentence_token_2_nltk + (max_len - len(sentence_token_2_nltk)) * [np.nan]\n",
    "sentence_token_3_nltk = sentence_token_3_nltk + (max_len - len(sentence_token_3_nltk)) * [np.nan]\n",
    "sentence_token_4_nltk = sentence_token_4_nltk + (max_len - len(sentence_token_4_nltk)) * [np.nan]\n",
    "\n",
    "# create a dataframe with the 4 variables (show NaN as empty space)\n",
    "df_token_nltk = pd.DataFrame({'Sentence 1': sentence_token_1_nltk, \n",
    "                              'Sentence 2': sentence_token_2_nltk, \n",
    "                              'Sentence 3': sentence_token_3_nltk, \n",
    "                              'Sentence 4': sentence_token_4_nltk}).fillna('')\n",
    "df_token_nltk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Form Word Stemming"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original TOKENS:  80\n",
      "['It', 'is', 'one', 'thing', 'to', 'automatically', 'detect', 'that', 'a', 'particular', 'word', 'occurs', 'in', 'a', 'text', ',', 'and', 'to', 'display', 'some', 'words', 'that', 'appear', 'in', 'the', 'same', 'context', '.', 'However', ',', 'we', 'can', 'also', 'determine', 'the', 'location', 'of', 'a', 'word', 'in', 'the', 'text', ':', 'how', 'many', 'words', 'from', 'the', 'beginning', 'it', 'appears', '.', 'This', 'positional', 'information', 'can', 'be', 'displayed', 'using', 'a', 'dispersion', 'plot', '.', 'Each', 'stripe', 'represents', 'an', 'instance', 'of', 'a', 'word', ',', 'and', 'each', 'row', 'represents', 'the', 'entire', 'text', '.']\n",
      "\n",
      "RegEx Stemming:  80\n",
      "['It', 'i', 'one', 'th', 'to', 'automatical', 'detect', 'that', 'a', 'particular', 'word', 'occur', 'in', 'a', 'text', ',', 'and', 'to', 'display', 'some', 'word', 'that', 'appear', 'in', 'the', 'same', 'context', '.', 'However', ',', 'we', 'can', 'also', 'determine', 'the', 'location', 'of', 'a', 'word', 'in', 'the', 'text', ':', 'how', 'many', 'word', 'from', 'the', 'beginn', 'it', 'appear', '.', 'Thi', 'positional', 'information', 'can', 'be', 'display', 'us', 'a', 'dispersion', 'plot', '.', 'Each', 'stripe', 'represent', 'an', 'instance', 'of', 'a', 'word', ',', 'and', 'each', 'row', 'represent', 'the', 'entire', 'text', '.']\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import nltk\n",
    "\n",
    "def stem(word):\n",
    "    regexp = r'^(.*?)(ing|ly|ed|ious|ies|ive|es|s|ment)?$'\n",
    "    stem, suffix = re.findall(regexp, word)[0]\n",
    "    return stem\n",
    "\n",
    "tokens = nltk.tokenize.word_tokenize(data1) # Word Tokenization\n",
    "\n",
    "print(\"Original TOKENS: \", len(tokens))\n",
    "print(tokens)\n",
    "print()\n",
    "print(\"RegEx Stemming: \", len([stem(t) for t in tokens]))\n",
    "print([stem(t) for t in tokens])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porter Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original TOKENS:  80\n",
      "['It', 'is', 'one', 'thing', 'to', 'automatically', 'detect', 'that', 'a', 'particular', 'word', 'occurs', 'in', 'a', 'text', ',', 'and', 'to', 'display', 'some', 'words', 'that', 'appear', 'in', 'the', 'same', 'context', '.', 'However', ',', 'we', 'can', 'also', 'determine', 'the', 'location', 'of', 'a', 'word', 'in', 'the', 'text', ':', 'how', 'many', 'words', 'from', 'the', 'beginning', 'it', 'appears', '.', 'This', 'positional', 'information', 'can', 'be', 'displayed', 'using', 'a', 'dispersion', 'plot', '.', 'Each', 'stripe', 'represents', 'an', 'instance', 'of', 'a', 'word', ',', 'and', 'each', 'row', 'represents', 'the', 'entire', 'text', '.']\n",
      "\n",
      "Porter Stemmer:  80\n",
      "['it', 'is', 'one', 'thing', 'to', 'automat', 'detect', 'that', 'a', 'particular', 'word', 'occur', 'in', 'a', 'text', ',', 'and', 'to', 'display', 'some', 'word', 'that', 'appear', 'in', 'the', 'same', 'context', '.', 'howev', ',', 'we', 'can', 'also', 'determin', 'the', 'locat', 'of', 'a', 'word', 'in', 'the', 'text', ':', 'how', 'mani', 'word', 'from', 'the', 'begin', 'it', 'appear', '.', 'thi', 'posit', 'inform', 'can', 'be', 'display', 'use', 'a', 'dispers', 'plot', '.', 'each', 'stripe', 'repres', 'an', 'instanc', 'of', 'a', 'word', ',', 'and', 'each', 'row', 'repres', 'the', 'entir', 'text', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "ps = nltk.stem.PorterStemmer()\n",
    "tokens = nltk.tokenize.word_tokenize(data1) # Word Tokenization\n",
    "\n",
    "print(\"Original TOKENS: \", len(tokens))\n",
    "print(tokens)\n",
    "print()\n",
    "print(\"Porter Stemmer: \", len([ps.stem(t) for t in tokens]))\n",
    "print([ps.stem(t) for t in tokens])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lancaster Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original TOKENS:  80\n",
      "['It', 'is', 'one', 'thing', 'to', 'automatically', 'detect', 'that', 'a', 'particular', 'word', 'occurs', 'in', 'a', 'text', ',', 'and', 'to', 'display', 'some', 'words', 'that', 'appear', 'in', 'the', 'same', 'context', '.', 'However', ',', 'we', 'can', 'also', 'determine', 'the', 'location', 'of', 'a', 'word', 'in', 'the', 'text', ':', 'how', 'many', 'words', 'from', 'the', 'beginning', 'it', 'appears', '.', 'This', 'positional', 'information', 'can', 'be', 'displayed', 'using', 'a', 'dispersion', 'plot', '.', 'Each', 'stripe', 'represents', 'an', 'instance', 'of', 'a', 'word', ',', 'and', 'each', 'row', 'represents', 'the', 'entire', 'text', '.']\n",
      "\n",
      "Lancaster Stemmer:  80\n",
      "['it', 'is', 'on', 'thing', 'to', 'autom', 'detect', 'that', 'a', 'particul', 'word', 'occ', 'in', 'a', 'text', ',', 'and', 'to', 'display', 'som', 'word', 'that', 'appear', 'in', 'the', 'sam', 'context', '.', 'howev', ',', 'we', 'can', 'also', 'determin', 'the', 'loc', 'of', 'a', 'word', 'in', 'the', 'text', ':', 'how', 'many', 'word', 'from', 'the', 'begin', 'it', 'appear', '.', 'thi', 'posit', 'inform', 'can', 'be', 'display', 'us', 'a', 'dispers', 'plot', '.', 'each', 'stripe', 'repres', 'an', 'inst', 'of', 'a', 'word', ',', 'and', 'each', 'row', 'repres', 'the', 'entir', 'text', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "ls = nltk.stem.LancasterStemmer()\n",
    "tokens = nltk.tokenize.word_tokenize(data1) # Word Tokenization\n",
    "\n",
    "print(\"Original TOKENS: \", len(tokens))\n",
    "print(tokens)\n",
    "print()\n",
    "print(\"Lancaster Stemmer: \", len([ls.stem(t) for t in tokens]))\n",
    "print([ls.stem(t) for t in tokens])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Filter Stop Words & Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text Corpus Length :  80\n",
      "Filtered Text Corpus Length :  36\n",
      "\n",
      "Original Text Corpus :\n",
      " ['it', 'is', 'one', 'thing', 'to', 'automatically', 'detect', 'that', 'a', 'particular', 'word', 'occurs', 'in', 'a', 'text', ',', 'and', 'to', 'display', 'some', 'words', 'that', 'appear', 'in', 'the', 'same', 'context', '.', 'however', ',', 'we', 'can', 'also', 'determine', 'the', 'location', 'of', 'a', 'word', 'in', 'the', 'text', ':', 'how', 'many', 'words', 'from', 'the', 'beginning', 'it', 'appears', '.', 'this', 'positional', 'information', 'can', 'be', 'displayed', 'using', 'a', 'dispersion', 'plot', '.', 'each', 'stripe', 'represents', 'an', 'instance', 'of', 'a', 'word', ',', 'and', 'each', 'row', 'represents', 'the', 'entire', 'text', '.']\n",
      "\n",
      "Filtered Text Corpus :\n",
      " ['one', 'thing', 'automatically', 'detect', 'particular', 'word', 'occurs', 'text', 'display', 'words', 'appear', 'context', 'however', 'also', 'determine', 'location', 'word', 'text', 'many', 'words', 'beginning', 'appears', 'positional', 'information', 'displayed', 'using', 'dispersion', 'plot', 'stripe', 'represents', 'instance', 'word', 'row', 'represents', 'entire', 'text']\n"
     ]
    }
   ],
   "source": [
    "import nltk, string\n",
    "\n",
    "# normalize data to lower case\n",
    "text_lower = data1.lower()\n",
    "# tokenize words\n",
    "word_tokens = nltk.tokenize.word_tokenize(text_lower)\n",
    "# get stop words from nltk library and punctuations from string library\n",
    "stop_tokens = nltk.corpus.stopwords.words(\"english\") + list(string.punctuation)\n",
    "filtered_tokens = []\n",
    "\n",
    "# filtering stop words and punctuations\n",
    "for w in word_tokens:\n",
    "    if w not in stop_tokens :\n",
    "        filtered_tokens.append(w)\n",
    "\n",
    "print(\"Original Text Corpus Length : \",len(word_tokens))\n",
    "print(\"Filtered Text Corpus Length : \",len(filtered_tokens))\n",
    "print(\"\\nOriginal Text Corpus :\\n\",word_tokens)\n",
    "print(\"\\nFiltered Text Corpus :\\n\",filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOPWORDS\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "\n",
      "PUNCTUATIONS\n",
      "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n"
     ]
    }
   ],
   "source": [
    "print(\"STOPWORDS\")\n",
    "print(nltk.corpus.stopwords.words(\"english\"))\n",
    "\n",
    "print(\"\\nPUNCTUATIONS\")\n",
    "print(list(string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stop Words In Text Corpus : 36\n",
      "['it', 'is', 'to', 'that', 'a', 'in', 'a', 'and', 'to', 'some', 'that', 'in', 'the', 'same', 'we', 'can', 'the', 'of', 'a', 'in', 'the', 'how', 'from', 'the', 'it', 'this', 'can', 'be', 'a', 'each', 'an', 'of', 'a', 'and', 'each', 'the']\n",
      "\n",
      "Punctuations In Text Corpus :8\n",
      "[',', '.', ',', ':', '.', '.', ',', '.']\n",
      "\n",
      "Stop Words In Text Corpus (without duplicates) :19\n",
      "['of', 'it', 'is', 'and', 'the', 'how', 'we', 'in', 'a', 'same', 'this', 'to', 'can', 'an', 'that', 'each', 'be', 'some', 'from']\n",
      "\n",
      "Punctuations In Text Corpus (without duplicates) :3\n",
      "['.', ',', ':']\n"
     ]
    }
   ],
   "source": [
    "# finding stop words and punctuations\n",
    "stop_words = []\n",
    "punctuations = []\n",
    "\n",
    "for w in word_tokens:\n",
    "    if w in nltk.corpus.stopwords.words(\"english\") :\n",
    "        stop_words.append(w)\n",
    "    elif w in list(string.punctuation):\n",
    "        punctuations.append(w)\n",
    "        \n",
    "print(f\"\\nStop Words In Text Corpus : {len(stop_words)}\\n{stop_words}\")\n",
    "print(f\"\\nPunctuations In Text Corpus :{len(punctuations)}\\n{punctuations}\")\n",
    "\n",
    "# remove duplicates\n",
    "print(f\"\\nStop Words In Text Corpus (without duplicates) :{len(list(set(stop_words)))}\\n{list(set(stop_words))}\")\n",
    "print(f\"\\nPunctuations In Text Corpus (without duplicates) :{len(list(set(punctuations)))}\\n{list(set(punctuations))}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. POS Taggers & Syntactic Analysers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The big black dog barked at the white cat and chased away.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data from Data_2.txt where each line is a string\n",
    "with open('Data_2.txt') as f:\n",
    "    data2 = f.readlines()\n",
    "    \n",
    "# remove whitespace characters like `\\n` at the end of each line\n",
    "data2 = [x.strip() for x in data2]\n",
    "data2 = ' '.join(data2)\n",
    "data2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK POS Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('big', 'JJ'),\n",
       " ('black', 'JJ'),\n",
       " ('dog', 'NN'),\n",
       " ('barked', 'VBD'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('white', 'JJ'),\n",
       " ('cat', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('chased', 'VBD'),\n",
       " ('away', 'RB'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk \n",
    "\n",
    "# tokenize words\n",
    "word_tokens = nltk.tokenize.word_tokenize(data2)\n",
    "# pos tagger\n",
    "nltk_tags = nltk.pos_tag(word_tokens)\n",
    "nltk_tags"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextBlob Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('big', 'JJ'),\n",
       " ('black', 'JJ'),\n",
       " ('dog', 'NN'),\n",
       " ('barked', 'VBD'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('white', 'JJ'),\n",
       " ('cat', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('chased', 'VBD'),\n",
       " ('away', 'RB')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "textblob_tags = TextBlob(data2).tags\n",
    "textblob_tags"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular Expression Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'NN'),\n",
       " ('big', 'NN'),\n",
       " ('black', 'NN'),\n",
       " ('dog', 'NN'),\n",
       " ('barked', 'VBD'),\n",
       " ('at', 'NN'),\n",
       " ('the', 'NN'),\n",
       " ('white', 'NN'),\n",
       " ('cat', 'NN'),\n",
       " ('and', 'NN'),\n",
       " ('chased', 'VBD'),\n",
       " ('away', 'NN'),\n",
       " ('.', 'NN')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "patterns = [\n",
    "     (r'.*ing$', 'VBG'),               # gerunds\n",
    "     (r'.*ed$', 'VBD'),                # simple past\n",
    "     (r'.*es$', 'VBZ'),                # 3rd singular present\n",
    "     (r'.*ould$', 'MD'),               # modals\n",
    "     (r'.*\\'s$', 'NN$'),               # possessive nouns\n",
    "     (r'.*s$', 'NNS'),                 # plural nouns\n",
    "     (r'^-?[0-9]+(.[0-9]+)?$', 'CD'),  # cardinal numbers\n",
    "     (r'.*', 'NN'),                    # nouns (default)\n",
    "     (r'^\\d+$', 'CD'),\n",
    "     (r'.*ing$', 'VBG'),               # gerunds, i.e. wondering\n",
    "     (r'.*ment$', 'NN'),               # i.e. wonderment\n",
    "     (r'.*ful$', 'JJ')                 # i.e. wonderful\n",
    "]\n",
    "\n",
    "# tokenize words\n",
    "word_tokens = nltk.tokenize.word_tokenize(data2)\n",
    "# register patterns to regex tagger\n",
    "regex_tagger = nltk.RegexpTagger(patterns)\n",
    "# tag the tokens\n",
    "regex_tags = regex_tagger.tag(word_tokens)\n",
    "regex_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<svg baseProfile=\"full\" height=\"360px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,560.0,360.0\" width=\"560px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"31.4286%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"22.7273%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">The</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"11.3636%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"77.2727%\" x=\"22.7273%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NOM</text></svg><svg width=\"29.4118%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">ADJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">big</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"14.7059%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"41.1765%\" x=\"29.4118%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">ADJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">black</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"29.4118%\" x=\"70.5882%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">dog</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"85.2941%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"61.3636%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"15.7143%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"68.5714%\" x=\"31.4286%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"60.4167%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"27.5862%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VB</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">barked</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"13.7931%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"72.4138%\" x=\"27.5862%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"19.0476%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">at</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"9.52381%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"80.9524%\" x=\"19.0476%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"29.4118%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">the</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"14.7059%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"70.5882%\" x=\"29.4118%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NOM</text></svg><svg width=\"58.3333%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">ADJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">white</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"29.1667%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"41.6667%\" x=\"58.3333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">cat</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"79.1667%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"64.7059%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"59.5238%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"63.7931%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"30.2083%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"10.4167%\" x=\"60.4167%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CC</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">and</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"65.625%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"29.1667%\" x=\"70.8333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"57.1429%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VB</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">chased</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"28.5714%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"42.8571%\" x=\"57.1429%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">away</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"78.5714%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"85.4167%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"65.7143%\" y1=\"1.2em\" y2=\"3em\" /></svg>",
      "text/plain": [
       "Tree('S', [Tree('NP', [Tree('DT', ['The']), Tree('NOM', [Tree('ADJ', ['big']), Tree('ADJ', ['black']), Tree('NN', ['dog'])])]), Tree('VP', [Tree('VP', [Tree('VB', ['barked']), Tree('PP', [Tree('IN', ['at']), Tree('NP', [Tree('DT', ['the']), Tree('NOM', [Tree('ADJ', ['white']), Tree('NN', ['cat'])])])])]), Tree('CC', ['and']), Tree('VP', [Tree('VB', ['chased']), Tree('IN', ['away'])])])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": "<svg baseProfile=\"full\" height=\"360px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,560.0,360.0\" width=\"560px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">S</text></svg><svg width=\"31.4286%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"22.7273%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">The</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"11.3636%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"77.2727%\" x=\"22.7273%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NOM</text></svg><svg width=\"29.4118%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">ADJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">big</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"14.7059%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"70.5882%\" x=\"29.4118%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NOM</text></svg><svg width=\"58.3333%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">ADJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">black</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"29.1667%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"41.6667%\" x=\"58.3333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">dog</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"79.1667%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"64.7059%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"61.3636%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"15.7143%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"68.5714%\" x=\"31.4286%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"60.4167%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"27.5862%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VB</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">barked</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"13.7931%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"72.4138%\" x=\"27.5862%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PP</text></svg><svg width=\"19.0476%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">at</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"9.52381%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"80.9524%\" x=\"19.0476%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NP</text></svg><svg width=\"29.4118%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">DT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">the</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"14.7059%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"70.5882%\" x=\"29.4118%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NOM</text></svg><svg width=\"58.3333%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">ADJ</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">white</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"29.1667%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"41.6667%\" x=\"58.3333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">NN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">cat</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"79.1667%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"64.7059%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"59.5238%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"63.7931%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"30.2083%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"10.4167%\" x=\"60.4167%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CC</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">and</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"65.625%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"29.1667%\" x=\"70.8333%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VP</text></svg><svg width=\"57.1429%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">VB</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">chased</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"28.5714%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"42.8571%\" x=\"57.1429%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IN</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">away</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"78.5714%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"85.4167%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"65.7143%\" y1=\"1.2em\" y2=\"3em\" /></svg>",
      "text/plain": [
       "Tree('S', [Tree('NP', [Tree('DT', ['The']), Tree('NOM', [Tree('ADJ', ['big']), Tree('NOM', [Tree('ADJ', ['black']), Tree('NN', ['dog'])])])]), Tree('VP', [Tree('VP', [Tree('VB', ['barked']), Tree('PP', [Tree('IN', ['at']), Tree('NP', [Tree('DT', ['the']), Tree('NOM', [Tree('ADJ', ['white']), Tree('NN', ['cat'])])])])]), Tree('CC', ['and']), Tree('VP', [Tree('VB', ['chased']), Tree('IN', ['away'])])])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw possible parse trees for the given sentence using nltk.CFG.fromstring\n",
    "import nltk\n",
    "\n",
    "parse_tree = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "NP -> DT NOM | DT NN | NP PP | NP CC NP\n",
    "NOM -> ADJ NOM | ADJ NN | ADJ ADJ NN\n",
    "VP -> VB NP | VB PP | VP CC VP | VB IN | VP CC VP\n",
    "PP -> IN NP\n",
    "DT -> 'The' | 'the'\n",
    "NN -> 'dog' | 'cat'\n",
    "VB -> 'barked' | 'chased'\n",
    "ADJ -> 'big' | 'black' | 'white'\n",
    "IN -> 'at' | 'away'\n",
    "CC -> 'and'\n",
    "\"\"\")\n",
    "parser = nltk.ChartParser(parse_tree)\n",
    "word_tokens = nltk.tokenize.word_tokenize(data2)\n",
    "\n",
    "for tree in parser.parse(word_tokens[:-1]):\n",
    "    display(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1a4a2f3c51900e879c65470871c76860eabd5596e5067eeaa31aed8adcbad33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
